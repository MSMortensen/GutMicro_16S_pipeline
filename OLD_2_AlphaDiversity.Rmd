---
title: "CEFTA Microbiome Alpha Diversity"
author: "masmo"
date: "`r Sys.Date()`"
output:
  rmdformats::readthedown:
    toc_depth: 4
    collapsed: false
    code_folding: hide
    number_sections: true
knit: (function(inputFile, encoding) { 
    rmarkdown::render(
        inputFile, encoding = encoding,
        output_dir = file.path(dirname(inputFile),"output"),
        output_file = paste0("CEFTA_", Sys.Date(), "_AlphaDiversity.html")) 
    })
params:
    input: "R_objects/Phyloseq_harsh.Rdata"
    batch: "Run"
---

# ALPHA DIVERSITY {.tabset .tabset-fade .tabset-pills}

This Rmarkdown contains the commands necessary to perform alpha diversity analysis of the output from the DF_GMH_PIPELINE. It is expected that the data has been imported, cleaned, and saved following the script 1_Import_QC.Rmd prior to using this script. I recommend visiting the ["Analysis of community ecology data in R"](https://www.davidzeleny.net/anadat-r/doku.php/en:start) to read about the theory behind the alpha and beta diversity and examples of the necessary R-code to execute them. Other excellent source of help is the R [cheat-sheets](https://www.rstudio.com/resources/cheatsheets/) and for problems related to Rmarkdown I suggest this [online Book](https://bookdown.org/yihui/rmarkdown/).

Alpha diversity, also called "within sample diversity" is calculated for each sample individually and is independent of all other samples. Alpha diversity is sensitive to sequencing depth, so rarefaction must be done first.

## SETUP

```{r setup, eval=TRUE, echo=TRUE, message=FALSE,warning = FALSE}
knitr::opts_chunk$set(echo = TRUE)

# Load libraries
library(tidyverse)
library(phyloseq)
library(ggpubr)
library(rstatix)
library(kableExtra)
library(picante)

# Create used folders if missing
if (!file.exists("R_objects")) dir.create(file.path(getwd(), "R_objects"))
if (!file.exists("plots")) dir.create(file.path(getwd(), "plots"))
if (!file.exists("tables")) dir.create(file.path(getwd(), "tables"))
if (!file.exists("scripts")) dir.create(file.path(getwd(), "scripts"))

# Save params
saveRDS(params, file = "R_objects/Adiv_params.RDS")
```

## SCRIPTS {.tabset .tabset-fade .tabset-pills}

### INFO

This section contains the scripts for the custom functions used in this pipeline

### ALPHA DIVERSITY

Alpha diversity is sensitive to sequencing depth, especially richness based metrics will increase with sequencing depth. To avoid any such bias rarefaction should be performed. Rarefaction

```{r Alpha_diversity_functions, eval=TRUE, echo=TRUE}

# Rarefaction curves
Rcurve_data <- function(physeq, ntables=10, step=250,maxdepth = max(sample_sums(physeq)), methods=c("Observed","Chao1","ACE","Shannon","FaithPD"), seedstart=500, verbose=FALSE) {
  require("vegan")
  require("picante")
  
  # prep list of 
  step.seq <- seq(from = 1, to = maxdepth, by = step)
  
  # Calculate alpha diversity
  rare_tab <- lapply(step.seq,function(k) Calculate_alpha_div(physeq = physeq, ntables = ntables, depth = k, methods = methods, seedstart = seedstart, verbose = verbose))
    
  # Format table
  rare_tab <- do.call(rbind, rare_tab)
  
  return(rare_tab)
}

# Calculate alpha diversity
Calculate_alpha_div <- function(physeq, ntables=100, depth = round(min(sample_sums(physeq))*0.9), methods=c("Observed","Chao1","FaithPD","Shannon"), seedstart=500, verbose=FALSE) {
  require("vegan")
  
  # remove samples below depth
  phy.use <- prune_samples(sample_sums(physeq) >= depth, physeq )
  
  # Orientate the OTU correctly
  if (taxa_are_rows(phy.use)){otu.tab<-unclass(t(otu_table(phy.use)))} else otu.tab <- unclass(otu_table(phy.use))
  
  # Rarefaction function
  rarefy <- function(x, depth) {
    y <- sample(rep(1:length(x), x), depth)
    y.tab <- table(y)
    j <- numeric(length(x))
    j[as.numeric(names(y.tab))] <- y.tab
    j
  }
  
  # Table to output alpha diversity table
  Alpha_diversity = data.frame(row.names = row.names(otu.tab))
  
  for (i in seq(length(methods))){
    Alpha_diversity[,methods[i]] <- numeric(length = nrow(otu.tab))
    Alpha_diversity[,paste0(methods[i],"_sd")] <- numeric(length = nrow(otu.tab))
  }
  
  # Run each sample separately
  for (z in 1:nrow(otu.tab)) {
    if (verbose==TRUE) {
      print(paste("Rarefaction sample number", z, sep=" "))
    }
    numbers <- otu.tab[z,]
    
    # Rarefy the sample ntables times
    set.seed(seedstart + z)
    rare_tab <- lapply(1:ntables,function(k) rarefy(numbers,depth))
    
    # Format table
    rare_tab <- do.call(rbind, rare_tab)
    
    # Calculate Observed richness, Chao1, and ACE.
    adiv <- data.frame(t(estimateR(rare_tab)))
    
    if ("Observed" %in% methods){
      # Save mean and sd of observed richness
      Alpha_diversity$Observed[z] <- mean(adiv$S.obs)
      Alpha_diversity$Observed_sd[z] <- sd(adiv$S.obs)
    }
    
    if ("Chao1" %in% methods){
      # Save mean and sd of observed richness
      Alpha_diversity$Chao1[z] <- mean(adiv$S.chao1)
      Alpha_diversity$Chao1_sd[z] <- sd(adiv$S.chao1)
    }
    
    if ("ACE" %in% methods){
      # Save mean and sd of observed richness
      Alpha_diversity$ACE[z] <- mean(adiv$se.ACE)
      Alpha_diversity$ACE_sd[z] <- sd(adiv$se.ACE)
    }
    
    if ("Shannon" %in% methods){
      # Calculate observed richness for each rep of sample z
      adiv <- vegan::diversity(rare_tab, index = "shannon")
      
      # Save mean and sd of observed richness
      Alpha_diversity$Shannon[z] <- mean(adiv)
      Alpha_diversity$Shannon_sd[z] <- sd(adiv)
    }
    
    if ("Simpson" %in% methods){
      # Calculate observed richness for each rep of sample z
      adiv <- diversity(rare_tab, index = "simpson")
      # Save mean and sd of observed richness
      Alpha_diversity$Simpson[z] <- mean(adiv)
      Alpha_diversity$Simpson_sd[z] <- sd(adiv)
    }
    
    if ("Evenness" %in% methods){
      # Calculate observed richness for each rep of sample z
      sha <- diversity(rare_tab, index = "shannon")
      obs <- rowSums(rare_tab != 0)
      adiv <- sha/log(obs)
      # Save mean and sd of observed richness
      Alpha_diversity$Evenness[z] <- mean(adiv)
      Alpha_diversity$Evenness_sd[z] <- sd(adiv)
    }
    
    if ("FaithPD" %in% methods){
      colnames(rare_tab) <- taxa_names(physeq)
      # Calculate Faith Phylogenetic distance for each rep of sample z
      tmp <- pd(rare_tab, phy_tree(physeq), include.root = T)
      Alpha_diversity$FaithPD[z] <- mean(tmp$PD)
      Alpha_diversity$FaithPD_sd[z] <- sd(tmp$PD)
    }
    
  }

  # Add alpha diversity to sample data
  output <- cbind(sample_data(phy.use),Alpha_diversity)
  output$depth = depth
  # Return physeq to the environment
  return(output) 
}

# save functions
save(Calculate_alpha_div, Rcurve_data, file = "scripts/adiv.Rdata")

# clear the environment and release memory
rm(list = ls(all.names = TRUE)) #will clear all objects includes hidden objects.
invisible(gc()) #free up memory and report the memory usage.

```

## CALCULATE ALPHA DIVERSITY

There is randomness involved in performing rarefaction (random subsampling). To minimize any effect of this randomness it is recommended to use the mean of multiple rarefactions instead of just relying on just one random subsampling. Not rarefying a sample can create a bias, so to avoid this I will rarefy all samples to 90% of the lowest sample depth (default setting). As this will be done for just one sequencing depth and we need the results to be consistent default setting is to rarefy 100 times. The function will produce a data.frame with sample metadata and the mean and standard deviation for each sample using the methods set prior.

```{r alpha_div_calc, eval=FALSE}

params <- readRDS("R_objects/Adiv_params.RDS")

# load data
load(params$input)
load("scripts/adiv.Rdata")

INDECES <- c("Observed","Shannon", "FaithPD", "Chao1")
# Calculate data
adat <- Calculate_alpha_div(phy, methods = INDECES)

# Save the phyloseq object
save(adat, INDECES, file="R_objects/AlphaDiversity.RData")

# clear the environment and release memory
rm(list = ls(all.names = TRUE)) #will clear all objects includes hidden objects.
invisible(gc()) #free up memory and report the memory usage.

```

## BATCH EFFECTS

Before testing any of the project specific variables it is important to determine if there is any batch effects that affect the samples (for example extraction batches or sequencing run)

```{r alpha_div_batch, eval=TRUE}

params <- readRDS("R_objects/Adiv_params.RDS")
# Load data
load("R_objects/AlphaDiversity.RData")

# Test normality (if all p > 0.05 parametric tests can be used)
adat %>% group_by(get(params$batch)) %>% shapiro_test(Observed)

### Test observed richness overall
FORMULA <- as.formula(paste("Observed ~", params$batch, sep = " "))
compare_means(FORMULA,  data = adat, method = "kruskal")

## If significant:
# Perform pairwise comparisons
stat.test <- adat %>%
  wilcox_test(FORMULA) %>%
  adjust_pvalue(method = "BH") %>%
  add_significance("p.adj") %>% 
  add_x_position(x = params$batch) %>%
  p_format("p.adj", accuracy = 0.0001, trailing.zero = TRUE, new.col = TRUE)

# Format for 
if (sum(stat.test$p.adj.signif != "ns") == 0) {
  stat.sig <- stat.test %>%
    add_y_position(step.increase = 0.25) %>%
    mutate(y.position = seq(min(y.position), max(y.position),length.out = n()))
} else {
  stat.sig <- stat.test[stat.test$p.adj.signif != "ns",] %>%
    add_y_position(step.increase = 0.25) %>%
    mutate(y.position = seq(min(y.position), max(y.position),length.out = n()))
}

# Create plot
p <- ggboxplot(adat, x = params$batch, y = "Observed",
          color = params$batch, palette = "jco",
          add = "jitter")

p.obs <- p + stat_pvalue_manual(stat.sig, label = "p.adj.format",tip.length = 0)

### Test shannon diversity index
# Test normality (if all p > 0.05 parametric tests can be used)
adat %>% group_by(get(params$batch)) %>% shapiro_test(Shannon)

# Run statistical test of batch effect
FORMULA <- as.formula(paste("Shannon ~", params$batch, sep = " "))
compare_means(FORMULA,  data = adat, method = "kruskal")

## If significant:
# Perform pairwise comparisons
stat.test <- adat %>%
  wilcox_test(FORMULA) %>%
  adjust_pvalue(method = "BH") %>%
  add_significance("p.adj") %>% 
  add_x_position(x = params$batch) %>%
  p_format("p.adj", accuracy = 0.0001, trailing.zero = TRUE, new.col = TRUE)

# Format for 
if (sum(stat.test$p.adj.signif != "ns") == 0) {
  stat.sig <- stat.test %>%
    add_y_position(step.increase = 0.25) %>%
    mutate(y.position = seq(min(y.position), max(y.position),length.out = n()))
} else {
  stat.sig <- stat.test[stat.test$p.adj.signif != "ns",] %>%
    add_y_position(step.increase = 0.25) %>%
    mutate(y.position = seq(min(y.position), max(y.position),length.out = n()))
}

# Create plot
p <- ggboxplot(adat, x = params$batch, y = "Shannon", color = params$batch, palette = "jco", add = "jitter")

p.sdi <- p + stat_pvalue_manual(stat.sig, label = "p.adj.format",tip.length = 0)
# If there is a significant batch effect, then it will be necessary to correct following tests for this effect.

### Test Faith phylogenetic distance
# Test normality (if all p > 0.05 parametric tests can be used)
adat %>% group_by(get(params$batch)) %>% shapiro_test(FaithPD)

# Run statistical test of batch effect
FORMULA <- as.formula(paste("FaithPD ~", params$batch, sep = " "))
compare_means(FORMULA,  data = adat, method = "kruskal")

## If significant:
# Perform pairwise comparisons
stat.test <- adat %>%
  wilcox_test(FORMULA) %>%
  adjust_pvalue(method = "BH") %>%
  add_significance("p.adj") %>% 
  add_x_position(x = params$batch) %>%
  p_format("p.adj", accuracy = 0.0001, trailing.zero = TRUE, new.col = TRUE)

# Format for 
if (sum(stat.test$p.adj.signif != "ns") == 0) {
  stat.sig <- stat.test %>%
    add_y_position(step.increase = 0.25) %>%
    mutate(y.position = seq(min(y.position), max(y.position),length.out = n()))
} else {
  stat.sig <- stat.test[stat.test$p.adj.signif != "ns",] %>%
    add_y_position(step.increase = 0.25) %>%
    mutate(y.position = seq(min(y.position), max(y.position),length.out = n()))
}

# Create plot
p <- ggboxplot(adat, x = params$batch, y = "FaithPD",
          color = params$batch, palette = "jco",
          add = "jitter")

p.fpd <- p + stat_pvalue_manual(stat.sig, label = "p.adj.format",tip.length = 0)

adiv_batch <- ggarrange(p.obs,p.sdi, p.fpd, nrow = 1, labels = c("A)","B)","C)"), common.legend = TRUE,legend = "bottom")
suppressMessages(ggsave(filename = "plots/adiv_batch.png",plot = adiv_batch, device = "png"))

# clear the environment and release memory
rm(list = ls(all.names = TRUE))
invisible(gc())

```

Boxplot of the influence of sequencing batches on alpha diversity: ![Batch effects on alpha diversity](plots/adiv_batch.png){width="100%"} As there is a batch effect it is important that we determine if any tested variables are independent of the batches or if there is an interaction.

# STATISTICAL TESTING

## THEORY

This section is copied from:
[Choosing the Right Statistical Test \| Types & Examples (scribbr.com)](https://www.scribbr.com/statistics/statistical-tests/)

### **What does a statistical test do?**

Statistical tests work by calculating a **test statistic** -- a number that describes how much the relationship between variables in your test differs from the null hypothesis of no relationship.

It then calculates a **p-value** (probability value). The p-value estimates how likely it is that you would see the difference described by the test statistic if the null hypothesis of no relationship were true.

If the value of the test statistic is more extreme than the statistic calculated from the null hypothesis, then you can infer a **statistically significant relationship** between the predictor and outcome variables.

If the value of the test statistic is less extreme than the one calculated from the null hypothesis, then you can infer **no statistically significant relationship** between the predictor and outcome variables.

### **When to perform a statistical test**

You can perform statistical tests on data that have been collected in a statistically valid manner -- either through an experiment, or through observations made using probability sampling methods.

For a statistical test to be valid, your sample size needs to be large enough to approximate the true distribution of the population being studied.

To determine which statistical test to use, you need to know:

-   whether your data meets certain assumptions.

-   the types of variables that you're dealing with.

### **Statistical assumptions**

Statistical tests make some common assumptions about the data they are testing:

1.  **Independence of observations** (a.k.a. no autocorrelation): The observations/variables you include in your test are not related (for example, multiple measurements of a single test subject are not independent, while measurements of multiple different test subjects are independent).

2.  **Homogeneity of variance**: the variance within each group being compared is similar among all groups. If one group has much more variation than others, it will limit the test's effectiveness.

3.  **Normality of data:** the data follows a normal distribution (a.k.a. a bell curve). This assumption applies only to quantitative data.

If your data do not meet the assumptions of normality or homogeneity of variance, you may be able to perform a **nonparametric statistical test**, which allows you to make comparisons without any assumptions about the data distribution.

If your data do not meet the assumption of independence of observations, you may be able to use a test that accounts for structure in your data (repeated-measures tests or tests that include blocking variables).

### **Types of variables**

The [types of variables](https://www.scribbr.com/methodology/types-of-variables/) you have usually determine what type of statistical test you can use.

**Quantitative variables** represent amounts of things (e.g. the number of trees in a forest). Types of quantitative variables include:

-   **Continuous** (a.k.a ratio variables): represent measures and can usually be divided into units smaller than one (e.g. 0.75 grams).

-   **Discrete** (a.k.a integer variables): represent counts and usually can't be divided into units smaller than one (e.g. 1 tree).

**Categorical variables** represent groupings of things (e.g. the different tree species in a forest). Types of categorical variables include:

-   **Ordinal**: represent data with an order (e.g. rankings).

-   **Nominal**: represent group names (e.g. brands or species names).

-   **Binary**: represent data with a yes/no or 1/0 outcome (e.g. win or lose).

Choose the test that fits the types of predictor and outcome variables you have collected. Consult the tables below to see which test best matches your variables.

### **Choosing the right test** {.tabset .tabset-fade .tabset-pills}

Parametric tests usually have stricter requirements than nonparametric tests, and are able to make stronger inferences from the data. They can only be conducted with data that adheres to the common assumptions of statistical tests.

Use the flowchart to choose the best parametric test for your data, then test that your data fullfill the statistical assumptions. If your data does not fulfill the assumptions, then choose the appropriate non-parametric test. More information are listed in the tabs below.

![flowchart for choosing a statistical test](flowchart-for-choosing-a-statistical-test.png)\

#### **Regression tests**

Regression tests look for **cause-and-effect relationships**. They can be used to estimate the effect of one or more continuous variables on another variable.

+----------------------------------------------------------------------------------------------+--------------------------+------------------+----------------------------------------------------------------------------+
|                                                                                              | Predictor variable       | Outcome variable | Research question example                                                  |
+:=============================================================================================+:========================:+:================:+:==========================================================================:+
| [Simple linear regression](https://www.scribbr.com/statistics/simple-linear-regression/)     | -   Continuous           | -   Continuous   | What is the effect of income on longevity?                                 |
|                                                                                              |                          |                  |                                                                            |
|                                                                                              | -   1 predictor          | -   1 outcome    |                                                                            |
+----------------------------------------------------------------------------------------------+--------------------------+------------------+----------------------------------------------------------------------------+
| [Multiple linear regression](https://www.scribbr.com/statistics/multiple-linear-regression/) | -   Continuous           | -   Continuous   | What is the effect of income and minutes of exercise per day on longevity? |
|                                                                                              |                          |                  |                                                                            |
|                                                                                              | -   2 or more predictors | -   1 outcome    |                                                                            |
+----------------------------------------------------------------------------------------------+--------------------------+------------------+----------------------------------------------------------------------------+
| Logistic regression                                                                          | -   Continuous           | -   Binary       | What is the effect of drug dosage on the survival of a test subject?       |
+----------------------------------------------------------------------------------------------+--------------------------+------------------+----------------------------------------------------------------------------+

#### **Comparison tests**

Comparison tests look for **differences among group means**. They can be used to test the effect of a categorical variable on the [mean value](https://www.scribbr.com/statistics/mean/) of some other characteristic.

[T-tests](https://www.scribbr.com/statistics/t-test/) are used when comparing the means of precisely two groups (e.g. the average heights of men and women). [ANOVA](https://www.scribbr.com/statistics/one-way-anova/) and MANOVA tests are used when comparing the means of more than two groups (e.g. the average heights of children, teenagers, and adults).

+--------------------+-------------------------+--------------------------------------------+---------------------------------------------------------------------------------------------------------------------+
|                    | Predictor variable      | Outcome variable                           | Research question example                                                                                           |
+:===================+:=======================:+:==========================================:+:===================================================================================================================:+
| Paired t-test      | -   Categorical         | -   Quantitative                           | What is the effect of two different test prep programs on the average exam scores for students from the same class? |
|                    |                         |                                            |                                                                                                                     |
|                    | -   1 predictor         | -   groups come from the same population   |                                                                                                                     |
+--------------------+-------------------------+--------------------------------------------+---------------------------------------------------------------------------------------------------------------------+
| Independent t-test | -   Categorical         | -   Quantitative                           | What is the difference in average exam scores for students from two different schools?                              |
|                    |                         |                                            |                                                                                                                     |
|                    | -   1 predictor         | -   groups come from different populations |                                                                                                                     |
+--------------------+-------------------------+--------------------------------------------+---------------------------------------------------------------------------------------------------------------------+
| ANOVA              | -   Categorical         | -   Quantitative                           | What is the difference in average pain levels among post-surgical patients given three different painkillers?       |
|                    |                         |                                            |                                                                                                                     |
|                    | -   1 or more predictor | -   1 outcome                              |                                                                                                                     |
+--------------------+-------------------------+--------------------------------------------+---------------------------------------------------------------------------------------------------------------------+
| MANOVA             | -   Categorical         | -   Quantitative                           | What is the effect of flower species on petal length, petal width, and stem length?                                 |
|                    |                         |                                            |                                                                                                                     |
|                    | -   1 or more predictor | -   2 or more outcome                      |                                                                                                                     |
+--------------------+-------------------------+--------------------------------------------+---------------------------------------------------------------------------------------------------------------------+

#### **Correlation tests**

[Correlation tests](https://www.scribbr.com/statistics/correlation-coefficient/) **check whether variables are related** without hypothesizing a cause-and-effect relationship.

These can be used to test whether two variables you want to use in (for example) a multiple regression test are autocorrelated.

+----------------+----------------------------+-------------------------------------------+
|                | Variables                  | Research question example                 |
+:===============+:==========================:+:=========================================:+
| Pearson\'s *r* | -   2 continuous variables | How are latitude and temperature related? |
+----------------+----------------------------+-------------------------------------------+

#### **Nonparametric test alternatives**

Non-parametric tests don\'t make as many assumptions about the data, and are useful when one or more of the common statistical assumptions are violated. However, the inferences they make aren\'t as strong as with parametric tests.

+---------------------------------+----------------------+--------------------------------------------+---------------------+
|                                 | Predictor variable   | Outcome variable                           | Use in place of...  |
+:================================+:====================:+:==========================================:+:===================:+
| Spearman\'s *r*                 | -   Quantitative     | -   Quantitative                           | Pearson\'s *r*      |
+---------------------------------+----------------------+--------------------------------------------+---------------------+
| Chi square test of independence | -   Categorical      | -   Categorical                            | Pearson\'s *r*      |
+---------------------------------+----------------------+--------------------------------------------+---------------------+
| Sign test                       | -   Categorical      | -   Quantitative                           | One-sample *t*-test |
+---------------------------------+----------------------+--------------------------------------------+---------------------+
| Kruskal--Wallis *H*             | -   Categorical      | -   Quantitative                           | ANOVA               |
|                                 |                      |                                            |                     |
|                                 | -   3 or more groups |                                            |                     |
+---------------------------------+----------------------+--------------------------------------------+---------------------+
| ANOSIM                          | -   Categorical      | -   Quantitative                           | MANOVA              |
|                                 |                      |                                            |                     |
|                                 | -   3 or more groups | -   2 or more outcome variables            |                     |
+---------------------------------+----------------------+--------------------------------------------+---------------------+
| Wilcoxon Rank-Sum test          | -   Categorical      | -   Quantitative                           | Independent t-test  |
|                                 |                      |                                            |                     |
|                                 | -   2 groups         | -   groups come from different populations |                     |
+---------------------------------+----------------------+--------------------------------------------+---------------------+
| Wilcoxon Signed-rank test       | -   Categorical      | -   Quantitative                           | Paired t-test       |
|                                 |                      |                                            |                     |
|                                 | -   2 groups         | -   groups come from the same population   |                     |
+---------------------------------+----------------------+--------------------------------------------+---------------------+

## TEST STATISTICAL ASSUMPTIONS

### Independence of observations

First we have to ensure that the variables we are testing are independent of each other.
Categorical variables should be compared using **Chi squared test of independence**.
Quantitative variables should first be tested to see if it follows a normal distribution, followed by **Pearson's r** or **Spearman's r**

#### Categorical variables

```{r cat_var_cor, eval = TRUE}

params <- readRDS("R_objects/Adiv_params.RDS")
# Load data
load("R_objects/AlphaDiversity.RData")

# This converts all character columns to factor (if only specific columns should be converted replace "where(is_character)" with "c(<col1>,<col2>,...)"
adat <- adat %>% mutate(across(where(is_character), as_factor))

# Create vector of categorical variables
cat_var <- adat %>% select_if(is.factor) %>% select(where(~n_distinct(.) > 1)) %>% colnames()

length(cat_var) # If less than 2 variables the following code should not be run

# Test the variables pairwise 
adat %>% 
  select(cat_var) %>% 
  colnames() %>% 
  combn(2) %>% 
  t() %>% 
  as_tibble() %>% 
  rowwise %>% 
  mutate(chisq_test = list(
    table(adat[[V1]], adat[[V2]]) %>% chisq.test()
    ),
    chisq_pval = chisq_test$p.value
    )

```
If any correlations are significant, both variables cannot be included in the same test

#### Continous variables

```{r con_var_cor, eval = TRUE}

# Select variables
num_var <- adat %>% select_if(is_numeric) %>% select(where(~n_distinct(.) > 1)) %>% colnames()

# Test all numeric variables against each other

```

### Homogeneity of variance

the variance within each group being compared is similar among all groups. If one group has much more variation than others, it will limit the test's effectiveness.

### Normality of data

:** the data follows a normal distribution (a.k.a. a bell curve). This assumption applies only to quantitative data.


## CATEGORICAL VARIABLES EFFECTS {.tabset .tabset-fade .tabset-pills}

Keeping in mind possible batch effects, now we can test for project effects. Depending on the project it might be best to test each variable individually or to perform a nested test of the variables. It is important to ensure that R has interpreted the selected variable as a factor, charactor variables will automatically be interpreted as factors, but variables that consists solely of numbers (numerical or integers) is interpreted as continous by R and must be transformed to be factors.

### WEEK (INDIVIDUAL)

Here is code to test alpha diversity for a single categorical variable. To change the variable, just update the TEST.VAR

```{r alpha_div_Week_independence, eval=TRUE}

params <- readRDS("R_objects/Adiv_params.RDS")
# Load data
load("R_objects/AlphaDiversity.RData")
TEST.VAR <- "Week_clean"

# Remove samples with incomplete metadata
adat <- adat[!is.na(adat[,TEST.VAR]),]
adat[,TEST.VAR] <- as.factor(adat[,TEST.VAR])

### Determine if any batch effect might influence your data
# Calculate distribution counts
freq.t <- with(adat, table(Run, Week_clean, exclude = NULL))
freq.t

# Determine distribution percentages
prop.table(freq.t,2)*100

# Test if any difference is significant (if not significant the batch effect should be negligible)
chisq_test(freq.t)
```

As there is no significant interaction identified by the chi^2^-test, we can ignore the batch effects when analysing the variable.

```{r alpha_div_Week_test, eval=TRUE, fig.cap="Boxplot of alpha diversity"}
################################################################################

adat <- adat[adat$FMT == 1,]
#### Test project variable
### Observed richness
FORMULA <- as.formula(paste("Observed ~", TEST.VAR, sep = " "))
compare_means(FORMULA,  data = adat, method = "kruskal")

## If significant:
# Perform pairwise comparisons
stat.test <- adat %>%
  wilcox_test(FORMULA) %>%
  adjust_pvalue(method = "BH") %>%
  add_significance("p.adj") %>% 
  add_x_position(x = TEST.VAR) %>%
  p_format("p.adj", accuracy = 0.0001, trailing.zero = TRUE, new.col = TRUE)

# Format for 
if (sum(stat.test$p.adj.signif != "ns") == 0) {
  stat.sig <- stat.test %>%
    add_y_position(step.increase = 0.25) %>%
    mutate(y.position = seq(min(y.position), max(y.position),length.out = n()))
} else {
  stat.sig <- stat.test[stat.test$p.adj.signif != "ns",] %>%
    add_y_position(step.increase = 0.25) %>%
    mutate(y.position = seq(min(y.position), max(y.position),length.out = n()))
}

# Create plot
p <- ggboxplot(adat, x = TEST.VAR, y = "Observed",
          color = TEST.VAR, palette = "jco",
          add = "jitter")

p.obs <- p + stat_pvalue_manual(stat.sig, label = "p.adj.format",tip.length = 0)

### Test shannon diversity index
# Run statistical test of batch effect
FORMULA <- as.formula(paste("Shannon ~", TEST.VAR, sep = " "))
compare_means(FORMULA,  data = adat, method = "kruskal")

## If significant:
# Perform pairwise comparisons
stat.test <- adat %>%
  wilcox_test(FORMULA) %>%
  adjust_pvalue(method = "BH") %>%
  add_significance("p.adj") %>% 
  add_x_position(x = TEST.VAR) %>%
  p_format("p.adj", accuracy = 0.0001, trailing.zero = TRUE, new.col = TRUE)

# Format for 
if (sum(stat.test$p.adj.signif != "ns") == 0) {
  stat.sig <- stat.test %>%
    add_y_position(step.increase = 0.25) %>%
    mutate(y.position = seq(min(y.position), max(y.position),length.out = n()))
} else {
  stat.sig <- stat.test[stat.test$p.adj.signif != "ns",] %>%
    add_y_position(step.increase = 0.25) %>%
    mutate(y.position = seq(min(y.position), max(y.position),length.out = n()))
}
# Create plot
p <- ggboxplot(adat, x = TEST.VAR, y = "Shannon", color = TEST.VAR, palette = "jco", add = "jitter")

p.sdi <- p + stat_pvalue_manual(stat.sig, label = "p.adj.format",tip.length = 0)

# Test Faith phylogenetic distance
FORMULA <- as.formula(paste("FaithPD ~", TEST.VAR, sep = " "))
compare_means(FORMULA,  data = adat, method = "kruskal")

## If significant:
# Perform pairwise comparisons
stat.test <- adat %>%
  wilcox_test(FORMULA) %>%
  adjust_pvalue(method = "BH") %>%
  add_significance("p.adj") %>% 
  add_x_position(x = TEST.VAR) %>%
  p_format("p.adj", accuracy = 0.0001, trailing.zero = TRUE, new.col = TRUE)

# Format for 
if (sum(stat.test$p.adj.signif != "ns") == 0) {
  stat.sig <- stat.test %>%
    add_y_position(step.increase = 0.25) %>%
    mutate(y.position = seq(min(y.position), max(y.position),length.out = n()))
} else {
  stat.sig <- stat.test[stat.test$p.adj.signif != "ns",] %>%
    add_y_position(step.increase = 0.25) %>%
    mutate(y.position = seq(min(y.position), max(y.position),length.out = n()))
}

# Create plot
p <- ggboxplot(adat, x = TEST.VAR, y = "FaithPD",
          color = TEST.VAR, palette = "jco",
          add = "jitter")

p.fpd <- p + stat_pvalue_manual(stat.sig, label = "p.adj.format",tip.length = 0)

# If there is a significant batch effect, then it will be necessary to correct following tests for this effect.
filename <- paste0("plots/adiv_",TEST.VAR,".png")
adiv_plot <- ggarrange(p.obs,p.sdi, p.fpd, nrow = 1, labels = c("A)","B)","C)"), common.legend = TRUE,legend = "bottom")
adiv_plot + ggtitle(paste0("Difference in alpha diversity between ",TEST.VAR,":"))
suppressMessages(ggsave(filename = filename, plot = adiv_plot, device = "png"))

# clear the environment and release memory
rm(list = ls(all.names = TRUE))
invisible(gc())
```

### OUTCOME (INDIVIDUAL)

Here is code to test alpha diversity for a single variable.

```{r alpha_div_outcome_independence, eval=TRUE}

params <- readRDS("R_objects/Adiv_params.RDS")
# Load data
load("R_objects/AlphaDiversity.RData")
TEST.VAR <- "Outcome2"

# Remove samples with incomplete metadata
adat <- adat[!is.na(adat[,TEST.VAR]),]
adat[,TEST.VAR] <- as.factor(adat[,TEST.VAR])

### Determine if any batch effect might influence your data
# Calculate distribution counts
freq.t <- with(adat, table(Run, Week_clean, exclude = NULL))
freq.t

# Determine distribution percentages
prop.table(freq.t,2)*100

# Test if any difference is significant (if not significant the batch effect should be negligible)
chisq_test(freq.t)
```

As there is no significant interaction identified by the chi^2^-test, we can ignore the batch effects when analysing the variable.

```{r alpha_div_outcome_test, eval=TRUE, fig.cap="Boxplot of alpha diversity"}
################################################################################

#### Test project variable
### Observed richness
FORMULA <- as.formula(paste("Observed ~", TEST.VAR, sep = " "))
compare_means(FORMULA,  data = adat, method = "kruskal")

## If significant:
# Perform pairwise comparisons
stat.test <- adat %>%
  wilcox_test(FORMULA) %>%
  adjust_pvalue(method = "BH") %>%
  add_significance("p.adj") %>% 
  add_x_position(x = TEST.VAR) %>%
  p_format("p.adj", accuracy = 0.0001, trailing.zero = TRUE, new.col = TRUE)

# Format for 
if (sum(stat.test$p.adj.signif != "ns") == 0) {
  stat.sig <- stat.test %>%
    add_y_position(step.increase = 0.25) %>%
    mutate(y.position = seq(min(y.position), max(y.position),length.out = n()))
} else {
  stat.sig <- stat.test[stat.test$p.adj.signif != "ns",] %>%
    add_y_position(step.increase = 0.25) %>%
    mutate(y.position = seq(min(y.position), max(y.position),length.out = n()))
}

# Create plot
p <- ggboxplot(adat, x = TEST.VAR, y = "Observed",
          color = TEST.VAR, palette = "jco",
          add = "jitter")

p.obs <- p + stat_pvalue_manual(stat.sig, label = "p.adj.format",tip.length = 0)

### Test shannon diversity index
# Run statistical test of batch effect
FORMULA <- as.formula(paste("Shannon ~", TEST.VAR, sep = " "))
compare_means(FORMULA,  data = adat, method = "kruskal")

## If significant:
# Perform pairwise comparisons
stat.test <- adat %>%
  wilcox_test(FORMULA) %>%
  adjust_pvalue(method = "BH") %>%
  add_significance("p.adj") %>% 
  add_x_position(x = TEST.VAR) %>%
  p_format("p.adj", accuracy = 0.0001, trailing.zero = TRUE, new.col = TRUE)

# Format for 
if (sum(stat.test$p.adj.signif != "ns") == 0) {
  stat.sig <- stat.test %>%
    add_y_position(step.increase = 0.25) %>%
    mutate(y.position = seq(min(y.position), max(y.position),length.out = n()))
} else {
  stat.sig <- stat.test[stat.test$p.adj.signif != "ns",] %>%
    add_y_position(step.increase = 0.25) %>%
    mutate(y.position = seq(min(y.position), max(y.position),length.out = n()))
}
# Create plot
p <- ggboxplot(adat, x = TEST.VAR, y = "Shannon", color = TEST.VAR, palette = "jco", add = "jitter")

p.sdi <- p + stat_pvalue_manual(stat.sig, label = "p.adj.format",tip.length = 0)

# Test Faith phylogenetic distance
FORMULA <- as.formula(paste("FaithPD ~", TEST.VAR, sep = " "))
compare_means(FORMULA,  data = adat, method = "kruskal")

## If significant:
# Perform pairwise comparisons
stat.test <- adat %>%
  wilcox_test(FORMULA) %>%
  adjust_pvalue(method = "BH") %>%
  add_significance("p.adj") %>% 
  add_x_position(x = TEST.VAR) %>%
  p_format("p.adj", accuracy = 0.0001, trailing.zero = TRUE, new.col = TRUE)

# Format for 
if (sum(stat.test$p.adj.signif != "ns") == 0) {
  stat.sig <- stat.test %>%
    add_y_position(step.increase = 0.25) %>%
    mutate(y.position = seq(min(y.position), max(y.position),length.out = n()))
} else {
  stat.sig <- stat.test[stat.test$p.adj.signif != "ns",] %>%
    add_y_position(step.increase = 0.25) %>%
    mutate(y.position = seq(min(y.position), max(y.position),length.out = n()))
}

# Create plot
p <- ggboxplot(adat, x = TEST.VAR, y = "FaithPD",
          color = TEST.VAR, palette = "jco",
          add = "jitter")

p.fpd <- p + stat_pvalue_manual(stat.sig, label = "p.adj.format",tip.length = 0)

# If there is a significant batch effect, then it will be necessary to correct following tests for this effect.
filename <- paste0("plots/adiv_",TEST.VAR,".png")
adiv_plot <- ggarrange(p.obs,p.sdi, p.fpd, nrow = 1, labels = c("A)","B)","C)"), common.legend = TRUE,legend = "bottom")
adiv_plot + ggtitle(paste0("Difference in alpha diversity between ",TEST.VAR,":"))
suppressMessages(ggsave(filename = filename, plot = adiv_plot, device = "png"))

# clear the environment and release memory
rm(list = ls(all.names = TRUE))
invisible(gc())
```

### WEEK AND OUTCOME (NESTED)

Testing two variables are used when there is a nested aspect in the analysis, for example difference in treatment at each timepoint, that would have the timepoint as the outer variable and treatment as the inner variable

```{r adiv_nested, eval = FALSE}

params <- readRDS("R_objects/Adiv_params.RDS")
# Load data
load("R_objects/AlphaDiversity.RData")

adat$Week_factor <- as.factor(adat$Week_clean)
INNER.VAR <- "Outcome2"
OUTER.VAR <- "Week_clean"

# Remove samples with incomplete metadata
adat <- adat[!is.na(adat[,INNER.VAR]) & !is.na(adat[,OUTER.VAR]),]
adat[,OUTER.VAR] <- as.factor(adat[,OUTER.VAR])
adat[,INNER.VAR] <- as.factor(adat[,INNER.VAR])

#### Test project variable
### Observed richness
fit <- aov(as.formula(paste("Observed ~", OUTER.VAR,"*",INNER.VAR, sep = " ")), data = adat)
anova(fit)
TukeyHSD(fit)

## Calculate stats for inner variable
# Perform pairwise comparisons
stat.test <- adat %>%
  group_by(.data[[OUTER.VAR]]) %>%
  wilcox_test(as.formula(paste("Observed ~", INNER.VAR, sep = " "))) %>%
  adjust_pvalue(method = "BH") %>%
  add_significance("p.adj") %>% 
  add_xy_position(x = OUTER.VAR, dodge = 0.8) %>%
  p_format("p.adj", accuracy = 0.0001, trailing.zero = TRUE, new.col = TRUE)

## Calculate stats for outer variable
# Perform pairwise comparisons
stat.test2 <- adat %>%
  wilcox_test(as.formula(paste("Observed ~", OUTER.VAR, sep = " "))) %>%
  adjust_pvalue(method = "BH") %>%
  add_significance("p.adj") %>% 
  add_xy_position(x = OUTER.VAR) %>%
  p_format("p.adj", accuracy = 0.0001, trailing.zero = TRUE, new.col = TRUE)

# Adjust y value for outer p-values
stat.test2$y.position <- max(stat.test$y.position)*1.1

# Create plot
p <- ggboxplot(adat, x = OUTER.VAR, y = "Observed",
          color = INNER.VAR, palette = "jco",
          add = "jitter")

# Add p-values
p.obs <- p + stat_pvalue_manual(stat.test, label = "p.adj.format",tip.length = 0)
p.obs <- p.obs + stat_pvalue_manual(stat.test2, label = "p.adj.format",tip.length = 0.02, step.increase = 0.1)

### Shannon diversity index
fit <- aov(as.formula(paste("Shannon ~", OUTER.VAR,"*",INNER.VAR, sep = " ")), data = adat)
anova(fit)
TukeyHSD(fit)

## Calculate stats for inner variable
# Perform pairwise comparisons
stat.test <- adat %>%
  group_by(.data[[OUTER.VAR]]) %>%
  wilcox_test(as.formula(paste("Shannon ~", INNER.VAR, sep = " "))) %>%
  adjust_pvalue(method = "BH") %>%
  add_significance("p.adj") %>% 
  add_xy_position(x = OUTER.VAR, dodge = 0.8) %>%
  p_format("p.adj", accuracy = 0.0001, trailing.zero = TRUE, new.col = TRUE)

## Calculate stats for outer variable
# Perform pairwise comparisons
stat.test2 <- adat %>%
  wilcox_test(as.formula(paste("Shannon ~", OUTER.VAR, sep = " "))) %>%
  adjust_pvalue(method = "BH") %>%
  add_significance("p.adj") %>% 
  add_xy_position(x = OUTER.VAR) %>%
  p_format("p.adj", accuracy = 0.0001, trailing.zero = TRUE, new.col = TRUE)

# Adjust y value for outer p-values
stat.test2$y.position <- max(stat.test$y.position)*1.1

# Create plot
p <- ggboxplot(adat, x = OUTER.VAR, y = "Shannon",
          color = INNER.VAR, palette = "jco",
          add = "jitter")

# Add p-values
p.sha <- p + stat_pvalue_manual(stat.test, label = "p.adj.format",tip.length = 0)
p.sha <- p.sha + stat_pvalue_manual(stat.test2, label = "p.adj.format",tip.length = 0.02, step.increase = 0.1)

### Create output plot
filename <- paste0("plots/adiv_",OUTER.VAR,"_",INNER.VAR,".png")
adiv_plot <- ggarrange(p.obs,p.sha, nrow = 1, labels = c("A)","B)"), common.legend = TRUE,legend = "bottom")
adiv_plot + ggtitle(paste0("Difference in alpha diversity between ",OUTER.VAR, " and ",INNER.VAR,":"))
suppressMessages(ggsave(filename = filename, plot = adiv_plot, device = "png"))


# clear the environment and release memory
rm(list = ls(all.names = TRUE)[ls(all.names = TRUE) != "params"])
invisible(gc())


```

## CONTIOUS VARIABLES EFFECTS {.tabset .tabset-fade .tabset-pills}

When testing contious variables I will recommend to first test for correlations between all relevant variables. If two or more variables are strongly correlated it is not necessary to test them all. Any identified batch effects should still be kept in mind when testing continous variables. Also it can be relevant to include information about categorical variables in the analysis. The procedure is based on the suggestions from Statistical tools for high-throughput data analysis ([STHDA](http://www.sthda.com/english/wiki/correlation-test-between-two-variables-in-r))

### THEORY

This section is a summary of information on the above mentioned website. For instance, if we are interested to know whether there is a relationship between the heights of fathers and sons, a correlation coefficient can be calculated to answer this question.

#### Methods for correlation analyses

There are different methods to perform **correlation analysis**:

##### Pearson correlation (r)

Pearson correlation measures a linear dependence between two variables (x and y). It's also known as a **parametric correlation** test because it depends to the distribution of the data. It can be used only when x and y are from normal distribution. The plot of $y=f(x)$ is named the **linear regression** curve.

##### Kendall rank correlation test

The Kendall rank correlation coefficient or Kendall's tau $(\tau)$ statistic is used to estimate a rank-based measure of association. This test may be used if the data do not necessarily come from a bivariate normal distribution.

##### Spearman rank correlation coefficient

Spearman's rho $(\rho)$ statistic is also used to estimate a rank-based measure of association. This test may be used if the data do not come from a bivariate normal distribution.

#### Correlation formula

In the formula below,

-   **x** and **y** are two vectors of length **n**

-   mxmx and mymy corresponds to the means of x and y, respectively.

**Pearson correlation formula**

$$\frac{\sum(x−m_{x})(y−m_{y})∑(x−mx)}{\sqrt{\sum(x−m_{x})^2\sum(y−m_{y})^2}}$$

$m_{x}$ and $m_{y}$ are the means of x and y variables.

The p-value (significance level) of the correlation can be determined :

1.  by using the correlation coefficient table for the degrees of freedom : $df=n−2$, where nn is the number of observation in x and y variables.

2.  or by calculating the **t value** as follow:

$$t = \frac{r}{\sqrt{1-r^2}}\sqrt{n-2} $$ In the case 2) the corresponding p-value is determined using [**t distribution table**](http://www.sthda.com/english/wiki/t-distribution-table) for $df=n−2$

**Spearman correlation formula** The Spearman correlation method computes the correlation between the rank of $x$ and the rank of $y$ variables. $$\rho=\frac{\sum(x'-m_{x'})(y'_{i}-m_{y'})}{\sqrt{\sum(x'-m_{x'})^2\sum(y'_{i}-m_{y'})^2}}$$ where $x'=rank(x)$ and $y'=rank(y)$.

**Kendall correlation formula** The Kendall correlation method measures the correspondence between the ranking of x and y variables. The total number of possible pairings of x with y observations is $n(n−1)/2$, where n is the size of x and y.

The procedure is as follow: - Begin by ordering the pairs by the x values. If x and y are correlated, then they would have the same relative rank orders. - Now, for each $y_{i}$, count the number of $y_{j}>y_{i}$ (**concordant pairs (c)**) and the number of $y_{j}<y_{i}$ (**discordant pairs (d)**).

**Kendall correlation distance** is defined as follow: $$\tau=\frac{n_{c}-n_{d}}{\frac{1}{2}n(n-1)}$$ Where, - $n_{c}$: total number of concordant pairs - $n_{d}$: total number of discordant pairs - $n$: size of x and y

### TEST VARIABLES

I do not have sufficient continous variables to test for interactions, but I will perform the test for the calculated alpha diversith indeces.

```{r cor_variables, eval=TRUE}

params <- readRDS("R_objects/Adiv_params.RDS")
# Load data
load("R_objects/AlphaDiversity.RData")

# create vector with the relevant variables (can also be subset by column indeces)
CON.VARS <- INDECES

# Plot all variables against each other
pairs(adat[,CON.VARS], pch = 19,  cex = 0.5,
      lower.panel=NULL)

# Run Pearson test
(corrmat <- cor(adat[,CON.VARS], method = "pearson", use = "complete.obs"))

# Create heatmap
corrmat_rounded <- round(corrmat, 2)

melted_corrmat_rounded <- tibble(Var1 = rep(row.names(corrmat_rounded), length(row.names(corrmat_rounded))),
                                 Var2 = rep(row.names(corrmat_rounded), each = length(row.names(corrmat_rounded))),
                                 dist = as.numeric(matrix(corrmat_rounded)))

ggplot(melted_corrmat_rounded, aes(x = Var1, y = Var2, fill = dist)) + 
  labs(title = "Correlation between continous variables") + 
  geom_tile(color = "white") + 
  scale_fill_gradient2(low = "blue", mid = "white", high = "red", midpoint = 0, limit = c(-1,1), 
                      space = "Lab", name = "Correlation coefficient") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, size = 12, hjust = 1, vjust = 1), 
        axis.text.y = element_text(size = 12, hjust = 1, vjust = 0.5),
        axis.title.x = element_blank(), axis.title.y = element_blank(),
        panel.grid.major = element_blank(),
        panel.border = element_blank(),
        panel.background = element_blank(),
        axis.ticks = element_blank()) + 
  geom_text(aes(x = Var1, y = Var2, label = dist), color = "black", size = 4) + 
  coord_fixed()

# The significance of any correlations can the be tested individually
with(adat, cor.test(Chao1,Observed, method = "pearson", use = "complete.obs"))
with(adat, cor.test(Chao1, DNA_Conc, method = "pearson", use = "complete.obs"))

# clear the environment and release memory
rm(list = ls(all.names = TRUE)[ls(all.names = TRUE) != "params"])
invisible(gc())
```

As we see that Observed, ACE, and Chao1 is strongly correlated there is no reason to test all of them so I will only test Observed richness.

### PERFORM CORRELATION TEST

First step is to determine if the variables are normally distributed.

```{r Adiv_prelim, eval=TRUE}

params <- readRDS("R_objects/Adiv_params.RDS")
# Load data
load("R_objects/AlphaDiversity.RData")

# store variables
INDEX <- "FaithPD"
VAR <- "DNA_Conc"

# Visualise data
ggscatter(adat, x = VAR, y = INDEX, # basic plot
          facet.by = params$batch, # This line can be commented out if alpha diversity is independent of batches
          add = "reg.line", conf.int = TRUE, # Adds a trendline with confidence interval
          cor.coef = TRUE, cor.method = "pearson") +  # performs a pearson test and show p-value 
  ggtitle("Preliminary visualization of data")

### Preliminary test of assumptions
## Create Q-Q plots
# Adiv plot
Q.ind <- ggqqplot(adat,x = INDEX)
# Variable plot
Q.var <- ggqqplot(adat, x = VAR)

filename <- paste0("plots/QQplot_",INDEX,"_",VAR,".png")
QQplot <- ggarrange(Q.ind,Q.var, nrow = 1, labels = c("A)","B)"), common.legend = TRUE,legend = "bottom")
QQplot + ggtitle(paste0("Q-Q plots for ",INDEX, " and ",VAR,":"))
suppressMessages(ggsave(filename = filename, plot = QQplot, device = "png"))

## Test for normal distribution using Shapiro test
# Shapiro-Wilk normality test for Adiv
shapiro.test(adat[,INDEX])
# Shapiro-Wilk normality test for Variable
shapiro.test(adat[,VAR])

```

To determine what test to use for the correlation analysis we must answer two questions:

1.  **Is the covariation linear?**

    -   In the situation where the scatter plots show curved patterns, we are dealing with nonlinear association between the two variables.

2.  **Are the data from each of the 2 variables (x, y) follow a normal distribution?** + **Visual inspection of the data normality using Q-Q plots (quantile-quantile plots)**.

    -   Q-Q plot draws the correlation between a given sample and the normal distribution. If the samples diverge from the trendline they are not normally distributed. + **From the Shapiro-Wilk normality test:** If the two p-values are greater than the significance level 0.05 it implies that the distribution of the data are not significantly different from normal distribution.

If it looks like the data follows the trendline in the preliminary plot we should test the correlation. If the test of normality determined that both variables are normally distributed we should use a **Pearson correlation** and if not we should use **Kendall correlation** or **Spearman correlation** (I prefer the latter)

```{r Adiv_continous_test}
# Set method
METHOD <- "spearman"

# Run test
cor.test(adat[,INDEX],adat[,VAR], method = METHOD)

# Create plot with correct correlation statistics
filename <- paste0("plots/CORplot_",INDEX,"_",VAR,".png")

ggscatter(adat, x = VAR, y = INDEX,
          facet.by = params$batch, # This line can be commented out if alpha diversity is independent of batches
          add = "reg.line", conf.int = TRUE, 
          cor.coef = TRUE, cor.method = METHOD)
suppressMessages(ggsave(filename = filename, device = "png"))

```

# SETTINGS {.tabset .tabset-fade .tabset-pills}

Overview of the parameters and packages that were used for this analysis

## PARAMETERS

The following paramenters were set in for this analysis:

```{r parameters, eval=TRUE}
params <- readRDS("R_objects/Adiv_params.RDS")

tmp <- unlist(params)
dat <- data.frame(Parameter = names(tmp), Value = unname(tmp))


kbl(dat, row.names = F) %>% kable_classic(lightable_options = "striped")

```

## PACKAGES

The analysis was run in R version `r getRversion()` using the following packages:

```{r packages, eval=TRUE}
pack <- data.frame(Package = (.packages()))

for (i in seq(nrow(pack))) pack$Version[i] <- as.character(packageVersion(pack$Package[i]))

kbl(pack[order(pack$Package),], row.names = F) %>% kable_classic(lightable_options = "striped")   
     
```
